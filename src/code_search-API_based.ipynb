{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fa689b3",
   "metadata": {},
   "source": [
    "## API Key Configuration\n",
    "\n",
    "**Security Note:** Never hardcode your API key in notebooks or commit it to version control.\n",
    "\n",
    "This notebook uses an LLM API for:\n",
    "- Generating hypothetical code snippets (HyDE)\n",
    "- Generating explanations for topic queries (RAG)\n",
    "\n",
    "All embeddings are still generated locally for efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893575b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ API key loaded from .env file\n",
      "\n",
      "  API key loaded successfully. It will NOT be displayed in any outputs.\n",
      "Key length: 56 characters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import getpass\n",
    "from typing import Optional\n",
    "\n",
    "def load_api_key() -> str:\n",
    "    \"\"\"\n",
    "    Securely load LLM API key from environment variable or user input.\n",
    "    The key is never printed or displayed in notebook outputs.\n",
    "    \"\"\"\n",
    "    # Try to load from environment variable first\n",
    "    api_key = os.environ.get('LLM_API_KEY')\n",
    "    \n",
    "    if api_key:\n",
    "        print(\"✓ API key loaded from environment variable\")\n",
    "        return api_key\n",
    "    \n",
    "    # Try to load from .env file\n",
    "    try:\n",
    "        from dotenv import load_dotenv\n",
    "        load_dotenv()\n",
    "        api_key = os.environ.get('LLM_API_KEY')\n",
    "        if api_key:\n",
    "            print(\"✓ API key loaded from .env file\")\n",
    "            return api_key\n",
    "    except ImportError:\n",
    "        pass\n",
    "    \n",
    "    # Prompt user for API key (not echoed to terminal)\n",
    "    print(\"API key not found in environment.\")\n",
    "    api_key = getpass.getpass(\"Enter your LLM API key: \")\n",
    "    \n",
    "    if not api_key or api_key.strip() == \"\":\n",
    "        raise ValueError(\"API key is required to use this notebook\")\n",
    "    \n",
    "    print(\"✓ API key entered manually (not saved)\")\n",
    "    return api_key.strip()\n",
    "\n",
    "# Load API key securely\n",
    "API_KEY = load_api_key()\n",
    "print(\"\\n  API key loaded successfully. It will NOT be displayed in any outputs.\")\n",
    "print(\"Key length:\", len(API_KEY), \"characters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1910",
   "metadata": {},
   "source": [
    "## 1. Importing and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9b5b03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev-copilot\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ All imports loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import time\n",
    "import re\n",
    "\n",
    "# Import utils functions\n",
    "sys.path.append(os.getcwd())\n",
    "from utils import find_repo_root, list_python_files\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tree_sitter_languages import get_parser\n",
    "import numpy as np\n",
    "\n",
    "print(\"✓ All imports loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09f1139",
   "metadata": {},
   "source": [
    "## 2. Configuration and LLM API Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31c366a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\dev-copilot\\env\\Lib\\site-packages\\tree_sitter\\__init__.py:36: FutureWarning: Language(path, name) is deprecated. Use Language(ptr, name) instead.\n",
      "  warn(\"{} is deprecated. Use {} instead.\".format(old, new), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading local embedding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACER\\.cache\\huggingface\\modules\\transformers_modules\\jinaai\\jina_hyphen_bert_hyphen_v2_hyphen_qk_hyphen_post_hyphen_norm\\3baf9e3ac750e76e8edd3019170176884695fb94\\configuration_bert.py:29: UserWarning: optimum is not installed. To use OnnxConfig and BertOnnxConfig, make sure that `optimum` package is installed\n",
      "  warnings.warn(\"optimum is not installed. To use OnnxConfig and BertOnnxConfig, make sure that `optimum` package is installed\")\n",
      "'(ReadTimeoutError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 38e4c505-fdc2-41be-8c91-eb91af3c3946)')' thrown while requesting HEAD https://huggingface.co/jinaai/jina-embeddings-v2-base-code/resolve/main/tokenizer_config.json\n",
      "Retrying in 1s [Retry 1/5].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Local embedding model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Repository and Database Configuration\n",
    "FLASK_REPO_PATH = \"../flask\"  # Adjust to your Flask repo location\n",
    "CHROMA_DB_PATH = \"../data/chroma_db_api\"\n",
    "COLLECTION_NAME = \"flask_code_api\"\n",
    "EMBEDDING_MODEL = \"jinaai/jina-embeddings-v2-base-code\"\n",
    "\n",
    "# LLM API Configuration (Groq)\n",
    "API_URL = \"https://api.groq.com/openai/v1/chat/completions\"\n",
    "MODEL_NAME = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# Initialize parser\n",
    "parser = get_parser(\"python\")\n",
    "\n",
    "# Load local embedding model\n",
    "print(\"Loading local embedding model...\")\n",
    "try:\n",
    "    embedding_model = SentenceTransformer(EMBEDDING_MODEL, trust_remote_code=True)\n",
    "    print(\"✓ Local embedding model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\" Error loading embedding model: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912a2402",
   "metadata": {},
   "source": [
    "## 3. LLM API Integration\n",
    "\n",
    "API-based functions for HyDE and RAG workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dc8f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing API connection...\n",
      "✓ API connection successful!\n",
      "  Model: llama-3.3-70b-versatile\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def call_llm_api(\n",
    "    prompt: str,\n",
    "    model: str = MODEL_NAME,\n",
    "    temperature: float = 0.3,\n",
    "    timeout: int = 60,\n",
    "    max_retries: int = 3,\n",
    "    max_tokens: int = 500\n",
    ") -> Optional[str]:\n",
    "    \"\"\"\n",
    "    Send a prompt to the LLM API and return the generated response.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The input prompt for the LLM\n",
    "        model: Model name\n",
    "        temperature: Sampling temperature\n",
    "        timeout: Request timeout in seconds\n",
    "        max_retries: Maximum number of retry attempts\n",
    "        max_tokens: Maximum tokens in response\n",
    "    \n",
    "    Returns:\n",
    "        The generated text response, or None if the request fails\n",
    "    \"\"\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"Bearer {API_KEY}\",\n",
    "        \"Content-Type\": \"application/json\"\n",
    "    }\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": [\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful code analysis assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        \"temperature\": temperature,\n",
    "        \"max_tokens\": max_tokens,\n",
    "        \"stop\": None\n",
    "    }\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = requests.post(API_URL, json=payload, headers=headers, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            result = response.json()\n",
    "            \n",
    "            if 'choices' in result and len(result['choices']) > 0:\n",
    "                return result['choices'][0]['message']['content'].strip()\n",
    "            else:\n",
    "                print(f\"  Unexpected API response format\")\n",
    "                return None\n",
    "                \n",
    "        except requests.exceptions.Timeout:\n",
    "            print(f\"  LLM request timed out (attempt {attempt + 1}/{max_retries})\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return None\n",
    "                \n",
    "        except requests.exceptions.HTTPError as e:\n",
    "            status_code = e.response.status_code\n",
    "            \n",
    "            if status_code == 429:\n",
    "                print(f\" Rate limit hit (attempt {attempt + 1}/{max_retries})\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 5 * (attempt + 1)\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    return None\n",
    "            elif status_code == 401:\n",
    "                print(f\" Authentication failed: Invalid API key\")\n",
    "                return None\n",
    "            else:\n",
    "                print(f\" HTTP error {status_code}: {e}\")\n",
    "                if attempt < max_retries - 1:\n",
    "                    wait_time = 2 ** attempt\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    return None\n",
    "                    \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\" Request failed: {e}\")\n",
    "            if attempt < max_retries - 1:\n",
    "                wait_time = 2 ** attempt\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                return None\n",
    "    \n",
    "    return None\n",
    "\n",
    "def test_api_connection() -> bool:\n",
    "    \"\"\"Test if the LLM API is accessible.\"\"\"\n",
    "    print(\"Testing API connection...\")\n",
    "    \n",
    "    test_prompt = \"Respond with only 'OK' if you can read this.\"\n",
    "    \n",
    "    try:\n",
    "        response = call_llm_api(test_prompt, timeout=30, max_retries=1, max_tokens=10)\n",
    "        \n",
    "        if response:\n",
    "            print(f\"✓ API connection successful!\")\n",
    "            print(f\"  Model: {MODEL_NAME}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(f\" API test failed - no response received\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\" API test failed: {e}\")\n",
    "        return False\n",
    "\n",
    "# Test the API connection\n",
    "test_api_connection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d135ff0",
   "metadata": {},
   "source": [
    "## 4. Code Parsing and Chunking\n",
    "\n",
    "(Same as original notebook - no changes needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "937f872c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Code parsing functions loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "def extract_code_chunks(file_path: str) -> List[Dict]:\n",
    "    \"\"\"Extract functions and classes from a Python file using tree-sitter.\"\"\"\n",
    "    chunks = []\n",
    "    \n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            code = f.read()\n",
    "        \n",
    "        tree = parser.parse(bytes(code, \"utf8\"))\n",
    "        root_node = tree.root_node\n",
    "        \n",
    "        def traverse(node, depth=0):\n",
    "            # Extract function definitions\n",
    "            if node.type == 'function_definition':\n",
    "                name_node = node.child_by_field_name('name')\n",
    "                if name_node:\n",
    "                    func_name = code[name_node.start_byte:name_node.end_byte]\n",
    "                    func_code = code[node.start_byte:node.end_byte]\n",
    "                    \n",
    "                    # Extract docstring if present\n",
    "                    docstring = \"\"\n",
    "                    body = node.child_by_field_name('body')\n",
    "                    if body and body.child_count > 0:\n",
    "                        first_child = body.children[0]\n",
    "                        if first_child.type == 'expression_statement':\n",
    "                            expr = first_child.children[0]\n",
    "                            if expr.type == 'string':\n",
    "                                docstring = code[expr.start_byte:expr.end_byte].strip('\"\"\"').strip(\"'''\").strip()\n",
    "                    \n",
    "                    chunks.append({\n",
    "                        'type': 'function',\n",
    "                        'name': func_name,\n",
    "                        'code': func_code,\n",
    "                        'docstring': docstring,\n",
    "                        'file_path': file_path,\n",
    "                        'start_line': node.start_point[0] + 1,\n",
    "                        'end_line': node.end_point[0] + 1,\n",
    "                    })\n",
    "            \n",
    "            # Extract class definitions\n",
    "            elif node.type == 'class_definition':\n",
    "                name_node = node.child_by_field_name('name')\n",
    "                if name_node:\n",
    "                    class_name = code[name_node.start_byte:name_node.end_byte]\n",
    "                    class_code = code[node.start_byte:node.end_byte]\n",
    "                    \n",
    "                    # Extract class docstring\n",
    "                    docstring = \"\"\n",
    "                    body = node.child_by_field_name('body')\n",
    "                    if body and body.child_count > 0:\n",
    "                        first_child = body.children[0]\n",
    "                        if first_child.type == 'expression_statement':\n",
    "                            expr = first_child.children[0]\n",
    "                            if expr.type == 'string':\n",
    "                                docstring = code[expr.start_byte:expr.end_byte].strip('\"\"\"').strip(\"'''\").strip()\n",
    "                    \n",
    "                    # Limit class code to avoid huge chunks\n",
    "                    if len(class_code) > 2000:\n",
    "                        class_code = class_code[:2000] + \"\\n    # ... (truncated)\"\n",
    "                    \n",
    "                    chunks.append({\n",
    "                        'type': 'class',\n",
    "                        'name': class_name,\n",
    "                        'code': class_code,\n",
    "                        'docstring': docstring,\n",
    "                        'file_path': file_path,\n",
    "                        'start_line': node.start_point[0] + 1,\n",
    "                        'end_line': node.end_point[0] + 1,\n",
    "                    })\n",
    "            \n",
    "            # Recursively traverse children\n",
    "            for child in node.children:\n",
    "                traverse(child, depth + 1)\n",
    "        \n",
    "        traverse(root_node)\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing {file_path}: {e}\")\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def create_searchable_text(chunk: Dict) -> str:\n",
    "    \"\"\"Create searchable text with prioritized metadata for embeddings.\"\"\"\n",
    "    parts = []\n",
    "    \n",
    "    # Prioritize docstring\n",
    "    if chunk['docstring']:\n",
    "        parts.append(f\"Documentation: {chunk['docstring']}\")\n",
    "    \n",
    "    # Add type and name\n",
    "    parts.append(f\"{chunk['type']}: {chunk['name']}\")\n",
    "    \n",
    "    # Add file path\n",
    "    file_name = chunk['file_path'].split('/')[-1] if '/' in chunk['file_path'] else chunk['file_path'].split('\\\\')[-1]\n",
    "    parts.append(f\"File: {file_name}\")\n",
    "    \n",
    "    # Add limited code\n",
    "    code_snippet = chunk['code'][:400]\n",
    "    parts.append(f\"Code:\\n{code_snippet}\")\n",
    "    \n",
    "    return \"\\n\\n\".join(parts)\n",
    "\n",
    "print(\"✓ Code parsing functions loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf76048",
   "metadata": {},
   "source": [
    "## 5. Indexing Pipeline\n",
    "\n",
    "(Same as original - uses local embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dfe29f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Indexing pipeline ready!\n"
     ]
    }
   ],
   "source": [
    "def index_repository(repo_path: str, force_reindex: bool = False):\n",
    "    \"\"\"Index all Python files in the repository.\"\"\"\n",
    "    \n",
    "    # Initialize ChromaDB\n",
    "    os.makedirs(CHROMA_DB_PATH, exist_ok=True)\n",
    "    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "    \n",
    "    # Get or create collection with COSINE similarity\n",
    "    try:\n",
    "        if force_reindex:\n",
    "            client.delete_collection(name=COLLECTION_NAME)\n",
    "            print(\"Deleted existing collection for reindexing.\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    collection = client.get_or_create_collection(\n",
    "        name=COLLECTION_NAME,\n",
    "        metadata={\n",
    "            \"description\": \"Flask repository code chunks with API-based search\",\n",
    "            \"hnsw:space\": \"cosine\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Check if already indexed\n",
    "    if collection.count() > 0 and not force_reindex:\n",
    "        print(f\"Repository already indexed with {collection.count()} chunks.\")\n",
    "        return collection\n",
    "    \n",
    "    # Get all Python files\n",
    "    print(f\"Finding Python files in {repo_path}...\")\n",
    "    py_files = list_python_files(repo_path)\n",
    "    print(f\"Found {len(py_files)} Python files.\")\n",
    "    \n",
    "    # Extract and index chunks\n",
    "    all_chunks = []\n",
    "    for i, file_path in enumerate(py_files):\n",
    "        if i % 10 == 0:\n",
    "            print(f\"Processing file {i+1}/{len(py_files)}...\")\n",
    "        \n",
    "        chunks = extract_code_chunks(file_path)\n",
    "        all_chunks.extend(chunks)\n",
    "    \n",
    "    print(f\"Extracted {len(all_chunks)} code chunks.\")\n",
    "    \n",
    "    if not all_chunks:\n",
    "        print(\"No code chunks found!\")\n",
    "        return collection\n",
    "    \n",
    "    # Generate embeddings in batches (LOCAL)\n",
    "    print(\"Generating embeddings locally...\")\n",
    "    batch_size = 32\n",
    "    indexed_count = 0\n",
    "    \n",
    "    for i in range(0, len(all_chunks), batch_size):\n",
    "        batch = all_chunks[i:i+batch_size]\n",
    "        texts = [create_searchable_text(chunk) for chunk in batch]\n",
    "        \n",
    "        # Generate embeddings locally\n",
    "        embeddings = embedding_model.encode(texts, show_progress_bar=False)\n",
    "        \n",
    "        # Prepare unique IDs\n",
    "        ids = [f\"{indexed_count + j}:{chunk['file_path']}:{chunk['name']}:{chunk['start_line']}\" \n",
    "               for j, chunk in enumerate(batch)]\n",
    "        \n",
    "        metadatas = [{\n",
    "            'type': chunk['type'],\n",
    "            'name': chunk['name'],\n",
    "            'file_path': chunk['file_path'],\n",
    "            'start_line': chunk['start_line'],\n",
    "            'end_line': chunk['end_line'],\n",
    "            'docstring': chunk['docstring'][:500] if chunk['docstring'] else \"\",\n",
    "        } for chunk in batch]\n",
    "        \n",
    "        documents = [chunk['code'] for chunk in batch]\n",
    "        \n",
    "        # Add to collection\n",
    "        collection.add(\n",
    "            ids=ids,\n",
    "            embeddings=embeddings.tolist(),\n",
    "            metadatas=metadatas,\n",
    "            documents=documents\n",
    "        )\n",
    "        \n",
    "        indexed_count += len(batch)\n",
    "        \n",
    "        if indexed_count % 100 == 0 or indexed_count == len(all_chunks):\n",
    "            print(f\"Indexed {indexed_count}/{len(all_chunks)} chunks...\")\n",
    "    \n",
    "    print(f\"✓ Indexing complete! Total chunks: {collection.count()}\")\n",
    "    return collection\n",
    "\n",
    "print(\"✓ Indexing pipeline ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c133ac",
   "metadata": {},
   "source": [
    "## 6. Query Type Detection\n",
    "\n",
    "Automatically detect whether a query is topic-focused (RAG) or code-specific (HyDE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12fde925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Type Detection Examples:\n",
      "  'How does Flask handle routing?' → TOPIC\n",
      "  'Show me the route decorator implementation' → CODE\n",
      "  'What is the request context?' → TOPIC\n",
      "  'Find error handling functions' → CODE\n"
     ]
    }
   ],
   "source": [
    "def detect_query_type(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Detect whether the query is a topic query (RAG) or code query (HyDE).\n",
    "    \n",
    "    Returns:\n",
    "        'topic': For high-level questions needing explanations (use RAG)\n",
    "        'code': For code-specific queries (use HyDE)\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Topic indicators (conceptual questions)\n",
    "    topic_indicators = [\n",
    "        'how does', 'how do', 'what is', 'what are', 'why does', 'why do',\n",
    "        'explain', 'describe', 'tell me about', 'work', 'understand',\n",
    "        'architecture', 'design', 'pattern', 'concept', 'mechanism'\n",
    "    ]\n",
    "    \n",
    "    # Code indicators (implementation requests)\n",
    "    code_indicators = [\n",
    "        'show me', 'find', 'function', 'class', 'method', 'implementation',\n",
    "        'code for', 'example of', 'sample', 'usage', 'api', 'interface'\n",
    "    ]\n",
    "    \n",
    "    # Check for topic indicators\n",
    "    topic_score = sum(1 for indicator in topic_indicators if indicator in query_lower)\n",
    "    \n",
    "    # Check for code indicators\n",
    "    code_score = sum(1 for indicator in code_indicators if indicator in query_lower)\n",
    "    \n",
    "    # Default to code if ambiguous or no clear indicators\n",
    "    if topic_score > code_score:\n",
    "        return 'topic'\n",
    "    else:\n",
    "        return 'code'\n",
    "\n",
    "# Test query type detection\n",
    "test_queries = [\n",
    "    \"How does Flask handle routing?\",\n",
    "    \"Show me the route decorator implementation\",\n",
    "    \"What is the request context?\",\n",
    "    \"Find error handling functions\"\n",
    "]\n",
    "\n",
    "print(\"Query Type Detection Examples:\")\n",
    "for query in test_queries:\n",
    "    qtype = detect_query_type(query)\n",
    "    print(f\"  '{query}' → {qtype.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73c5873",
   "metadata": {},
   "source": [
    "## 7. HyDE Code Search Implementation\n",
    "\n",
    "Generate hypothetical code via API, embed locally, and search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d2e1fd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ HyDE code search implementation loaded!\n"
     ]
    }
   ],
   "source": [
    "def hyde_code_search(query: str, top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    HyDE-based code search:\n",
    "    1. Generate hypothetical code snippet via LLM API\n",
    "    2. Embed the hypothetical code locally\n",
    "    3. Search for similar code chunks\n",
    "    \n",
    "    Args:\n",
    "        query: User's code search query\n",
    "        top_k: Number of results to return\n",
    "    \n",
    "    Returns:\n",
    "        List of relevant code chunks\n",
    "    \"\"\"\n",
    "    print(f\"\\n HyDE Code Search: '{query}'\")\n",
    "    \n",
    "    # Step 1: Generate hypothetical code via API\n",
    "    print(\"  → Generating hypothetical code via API...\")\n",
    "    hyde_prompt = f\"\"\"Generate a Python code snippet that would answer this query: \"{query}\"\n",
    "\n",
    "Requirements:\n",
    "- Write only valid Python code (no explanations)\n",
    "- Include function/class signatures with docstrings\n",
    "- Keep it concise (5-15 lines)\n",
    "- Focus on the core implementation\n",
    "\n",
    "Code:\"\"\"\n",
    "    \n",
    "    hypothetical_code = call_llm_api(hyde_prompt, temperature=0.3, max_tokens=300)\n",
    "    \n",
    "    if not hypothetical_code:\n",
    "        print(\"   Failed to generate hypothetical code, falling back to direct search\")\n",
    "        return direct_search(query, top_k)\n",
    "    \n",
    "    print(f\"  ✓ Generated {len(hypothetical_code)} characters of hypothetical code\")\n",
    "    \n",
    "    # Step 2: Embed the hypothetical code locally\n",
    "    print(\"  → Embedding hypothetical code locally...\")\n",
    "    hypothetical_embedding = embedding_model.encode([hypothetical_code])[0]\n",
    "    \n",
    "    # Step 3: Search for similar code chunks\n",
    "    print(\"  → Searching for similar code...\")\n",
    "    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "    \n",
    "    try:\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "    except:\n",
    "        print(\"   Collection not found. Please index the repository first.\")\n",
    "        return []\n",
    "    \n",
    "    results = collection.query(\n",
    "        query_embeddings=[hypothetical_embedding.tolist()],\n",
    "        n_results=top_k,\n",
    "        include=['metadatas', 'documents', 'distances']\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    formatted_results = []\n",
    "    if results['ids'] and results['ids'][0]:\n",
    "        for i in range(len(results['ids'][0])):\n",
    "            distance = results['distances'][0][i]\n",
    "            similarity = 1 - distance\n",
    "            \n",
    "            formatted_results.append({\n",
    "                'id': results['ids'][0][i],\n",
    "                'type': results['metadatas'][0][i]['type'],\n",
    "                'name': results['metadatas'][0][i]['name'],\n",
    "                'file_path': results['metadatas'][0][i]['file_path'],\n",
    "                'start_line': results['metadatas'][0][i]['start_line'],\n",
    "                'end_line': results['metadatas'][0][i]['end_line'],\n",
    "                'docstring': results['metadatas'][0][i]['docstring'],\n",
    "                'code': results['documents'][0][i],\n",
    "                'distance': distance,\n",
    "                'similarity': similarity,\n",
    "                'method': 'HyDE'\n",
    "            })\n",
    "    \n",
    "    print(f\"  ✓ Found {len(formatted_results)} results\\n\")\n",
    "    return formatted_results\n",
    "\n",
    "print(\"✓ HyDE code search implementation loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b0afb2",
   "metadata": {},
   "source": [
    "## 8. RAG Topic Query Implementation\n",
    "\n",
    "Retrieve relevant context and generate explanations via API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2865e206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ RAG topic query implementation loaded!\n"
     ]
    }
   ],
   "source": [
    "def rag_topic_query(query: str, top_k: int = 5, context_chunks: int = 3) -> Dict:\n",
    "    \"\"\"\n",
    "    RAG-based topic query:\n",
    "    1. Retrieve relevant code/doc chunks\n",
    "    2. Augment the query with retrieved context\n",
    "    3. Generate explanation via LLM API\n",
    "    \n",
    "    Args:\n",
    "        query: User's topic query\n",
    "        top_k: Number of chunks to retrieve\n",
    "        context_chunks: Number of chunks to use in LLM context\n",
    "    \n",
    "    Returns:\n",
    "        Dict with generated answer and supporting code chunks\n",
    "    \"\"\"\n",
    "    print(f\"\\n RAG Topic Query: '{query}'\")\n",
    "    \n",
    "    # Step 1: Retrieve relevant chunks using direct semantic search\n",
    "    print(\"  → Retrieving relevant code chunks...\")\n",
    "    retrieved_chunks = direct_search(query, top_k)\n",
    "    \n",
    "    if not retrieved_chunks:\n",
    "        print(\"    No relevant chunks found\")\n",
    "        return {\n",
    "            'answer': \"No relevant information found in the codebase.\",\n",
    "            'sources': []\n",
    "        }\n",
    "    \n",
    "    print(f\"  ✓ Retrieved {len(retrieved_chunks)} chunks\")\n",
    "    \n",
    "    # Step 2: Build context from top chunks\n",
    "    context_parts = []\n",
    "    for i, chunk in enumerate(retrieved_chunks[:context_chunks], 1):\n",
    "        context_parts.append(f\"### Source {i}: {chunk['type']} `{chunk['name']}` ({chunk['file_path']})\")\n",
    "        if chunk['docstring']:\n",
    "            context_parts.append(f\"Docstring: {chunk['docstring'][:200]}\")\n",
    "        context_parts.append(f\"Code:\\n```python\\n{chunk['code'][:500]}\\n```\")\n",
    "        context_parts.append(\"\")\n",
    "    \n",
    "    context = \"\\n\".join(context_parts)\n",
    "    \n",
    "    # Step 3: Generate answer via API\n",
    "    print(\"  → Generating explanation via API...\")\n",
    "    rag_prompt = f\"\"\"Answer this question about the Flask codebase: \"{query}\"\n",
    "\n",
    "Use ONLY the information provided below. Be specific and reference the code/functions mentioned.\n",
    "\n",
    "{context}\n",
    "\n",
    "Provide a clear, concise explanation (2-4 sentences) that directly answers the question.\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    answer = call_llm_api(rag_prompt, temperature=0.3, max_tokens=400)\n",
    "    \n",
    "    if not answer:\n",
    "        print(\"    Failed to generate answer\")\n",
    "        answer = \"Unable to generate answer due to API error.\"\n",
    "    else:\n",
    "        print(f\"  ✓ Generated answer ({len(answer)} characters)\\n\")\n",
    "    \n",
    "    return {\n",
    "        'answer': answer,\n",
    "        'sources': retrieved_chunks[:context_chunks],\n",
    "        'query': query,\n",
    "        'method': 'RAG'\n",
    "    }\n",
    "\n",
    "print(\"✓ RAG topic query implementation loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052034a9",
   "metadata": {},
   "source": [
    "## 9. Direct Search (Fallback)\n",
    "\n",
    "Traditional semantic search without HyDE or RAG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79e37a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Direct search implementation loaded!\n"
     ]
    }
   ],
   "source": [
    "def direct_search(query: str, top_k: int = 5) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Direct semantic search using query embedding.\n",
    "    Fallback when HyDE fails or for baseline comparison.\n",
    "    \"\"\"\n",
    "    client = chromadb.PersistentClient(path=CHROMA_DB_PATH)\n",
    "    \n",
    "    try:\n",
    "        collection = client.get_collection(name=COLLECTION_NAME)\n",
    "    except:\n",
    "        print(\"Collection not found. Please index the repository first.\")\n",
    "        return []\n",
    "    \n",
    "    # Generate query embedding\n",
    "    query_embedding = embedding_model.encode([query])[0]\n",
    "    \n",
    "    # Search\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding.tolist()],\n",
    "        n_results=top_k,\n",
    "        include=['metadatas', 'documents', 'distances']\n",
    "    )\n",
    "    \n",
    "    # Format results\n",
    "    formatted_results = []\n",
    "    if results['ids'] and results['ids'][0]:\n",
    "        for i in range(len(results['ids'][0])):\n",
    "            distance = results['distances'][0][i]\n",
    "            similarity = 1 - distance\n",
    "            \n",
    "            formatted_results.append({\n",
    "                'id': results['ids'][0][i],\n",
    "                'type': results['metadatas'][0][i]['type'],\n",
    "                'name': results['metadatas'][0][i]['name'],\n",
    "                'file_path': results['metadatas'][0][i]['file_path'],\n",
    "                'start_line': results['metadatas'][0][i]['start_line'],\n",
    "                'end_line': results['metadatas'][0][i]['end_line'],\n",
    "                'docstring': results['metadatas'][0][i]['docstring'],\n",
    "                'code': results['documents'][0][i],\n",
    "                'distance': distance,\n",
    "                'similarity': similarity,\n",
    "                'method': 'Direct'\n",
    "            })\n",
    "    \n",
    "    return formatted_results\n",
    "\n",
    "print(\"✓ Direct search implementation loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df69649e",
   "metadata": {},
   "source": [
    "## 10. Unified Search Interface\n",
    "\n",
    "Automatically route queries to HyDE or RAG based on query type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3800a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Unified search interface loaded!\n"
     ]
    }
   ],
   "source": [
    "def smart_search(query: str, top_k: int = 5, force_method: str = None) -> Dict:\n",
    "    \"\"\"\n",
    "    Unified search interface that automatically selects HyDE or RAG.\n",
    "    \n",
    "    Args:\n",
    "        query: User's search query\n",
    "        top_k: Number of results to return\n",
    "        force_method: Force a specific method ('hyde', 'rag', 'direct')\n",
    "    \n",
    "    Returns:\n",
    "        Dict with results and metadata\n",
    "    \"\"\"\n",
    "    # Detect query type if not forced\n",
    "    if force_method:\n",
    "        method = force_method.lower()\n",
    "    else:\n",
    "        query_type = detect_query_type(query)\n",
    "        method = 'hyde' if query_type == 'code' else 'rag'\n",
    "    \n",
    "    print(f\"Smart Search: {method.upper()} mode\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    \n",
    "    if method == 'hyde':\n",
    "        results = hyde_code_search(query, top_k)\n",
    "        return {\n",
    "            'method': 'HyDE',\n",
    "            'query': query,\n",
    "            'results': results,\n",
    "            'type': 'code'\n",
    "        }\n",
    "    \n",
    "    elif method == 'rag':\n",
    "        rag_result = rag_topic_query(query, top_k)\n",
    "        return {\n",
    "            'method': 'RAG',\n",
    "            'query': query,\n",
    "            'answer': rag_result['answer'],\n",
    "            'sources': rag_result['sources'],\n",
    "            'type': 'topic'\n",
    "        }\n",
    "    \n",
    "    else:  # direct\n",
    "        results = direct_search(query, top_k)\n",
    "        return {\n",
    "            'method': 'Direct',\n",
    "            'query': query,\n",
    "            'results': results,\n",
    "            'type': 'code'\n",
    "        }\n",
    "\n",
    "print(\"✓ Unified search interface loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f279c8",
   "metadata": {},
   "source": [
    "## 11. Display Functions\n",
    "\n",
    "Pretty print results for different search modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea502e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Display functions loaded!\n"
     ]
    }
   ],
   "source": [
    "def display_code_results(results: List[Dict]):\n",
    "    \"\"\"Display code search results (HyDE or Direct).\"\"\"\n",
    "    if not results:\n",
    "        print(\"No results found.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(results)} code results:\")\n",
    "    \n",
    "    for i, result in enumerate(results, 1):\n",
    "        print(f\"{i}. {result['type'].upper()}: {result['name']}\")\n",
    "        print(f\"   File: {result['file_path']}:{result['start_line']}-{result['end_line']}\")\n",
    "        print(f\"   Similarity: {result['similarity']:.4f} | Method: {result.get('method', 'N/A')}\")\n",
    "        \n",
    "        if result['docstring']:\n",
    "            doc_preview = result['docstring'][:150].replace('\\n', ' ')\n",
    "            print(f\"   Doc: {doc_preview}{'...' if len(result['docstring']) > 150 else ''}\")\n",
    "        \n",
    "        print(f\"   Code Preview:\")\n",
    "        code_lines = result['code'].split('\\n')[:6]\n",
    "        for line in code_lines:\n",
    "            if line.strip():\n",
    "                print(f\"      {line[:100]}\")\n",
    "        \n",
    "        total_lines = len(result['code'].split('\\n'))\n",
    "        if total_lines > 6:\n",
    "            print(f\"      ... ({total_lines - 6} more lines)\")\n",
    "        print()\n",
    "\n",
    "def display_topic_result(result: Dict):\n",
    "    \"\"\"Display RAG topic query result.\"\"\"\n",
    "    print(f\"RAG Topic Query Result\")\n",
    "    \n",
    "    print(f\"Query: {result['query']}\\n\")\n",
    "    print(f\"Answer:\\n{result['answer']}\\n\")\n",
    "    \n",
    "    print(f\"Supporting Sources ({len(result['sources'])}):\")\n",
    "    \n",
    "    for i, source in enumerate(result['sources'], 1):\n",
    "        print(f\"{i}. {source['type'].upper()}: {source['name']}\")\n",
    "        print(f\"   File: {source['file_path']}:{source['start_line']}-{source['end_line']}\")\n",
    "        print(f\"   Similarity: {source['similarity']:.4f}\")\n",
    "        \n",
    "        if source['docstring']:\n",
    "            print(f\"   Doc: {source['docstring'][:100]}...\")\n",
    "        \n",
    "        code_preview = source['code'].split('\\n')[:4]\n",
    "        print(f\"   Code:\")\n",
    "        for line in code_preview:\n",
    "            if line.strip():\n",
    "                print(f\"      {line[:80]}\")\n",
    "        print()\n",
    "\n",
    "def display_search_result(result: Dict):\n",
    "    \"\"\"Display any search result based on its type.\"\"\"\n",
    "    if result['type'] == 'topic':\n",
    "        display_topic_result(result)\n",
    "    else:\n",
    "        display_code_results(result['results'])\n",
    "\n",
    "print(\"✓ Display functions loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de593fc",
   "metadata": {},
   "source": [
    "## 12. Index the Repository\n",
    "\n",
    "Run this once to index your codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ccfb583",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding Python files in ../flask...\n",
      "Found 34 Python files.\n",
      "Processing file 1/34...\n",
      "Processing file 11/34...\n",
      "Processing file 21/34...\n",
      "Processing file 31/34...\n",
      "Extracted 448 code chunks.\n",
      "Generating embeddings locally...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Index the repository\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m collection = \u001b[43mindex_repository\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFLASK_REPO_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_reindex\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mindex_repository\u001b[39m\u001b[34m(repo_path, force_reindex)\u001b[39m\n\u001b[32m     56\u001b[39m texts = [create_searchable_text(chunk) \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Generate embeddings locally\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m embeddings = \u001b[43membedding_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;66;03m# Prepare unique IDs\u001b[39;00m\n\u001b[32m     62\u001b[39m ids = [\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindexed_count\u001b[38;5;250m \u001b[39m+\u001b[38;5;250m \u001b[39mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk[\u001b[33m'\u001b[39m\u001b[33mfile_path\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk[\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk[\u001b[33m'\u001b[39m\u001b[33mstart_line\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \n\u001b[32m     63\u001b[39m        \u001b[38;5;28;01mfor\u001b[39;00m j, chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(batch)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\utils\\_contextlib.py:115\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    114\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1094\u001b[39m, in \u001b[36mSentenceTransformer.encode\u001b[39m\u001b[34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, truncate_dim, pool, chunk_size, **kwargs)\u001b[39m\n\u001b[32m   1091\u001b[39m features.update(extra_features)\n\u001b[32m   1093\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m-> \u001b[39m\u001b[32m1094\u001b[39m     out_features = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.device.type == \u001b[33m\"\u001b[39m\u001b[33mhpu\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1096\u001b[39m         out_features = copy.deepcopy(out_features)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:1175\u001b[39m, in \u001b[36mSentenceTransformer.forward\u001b[39m\u001b[34m(self, input, **kwargs)\u001b[39m\n\u001b[32m   1169\u001b[39m             module_kwarg_keys = \u001b[38;5;28mself\u001b[39m.module_kwargs.get(module_name, [])\n\u001b[32m   1170\u001b[39m         module_kwargs = {\n\u001b[32m   1171\u001b[39m             key: value\n\u001b[32m   1172\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs.items()\n\u001b[32m   1173\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;28mhasattr\u001b[39m(module, \u001b[33m\"\u001b[39m\u001b[33mforward_kwargs\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module.forward_kwargs)\n\u001b[32m   1174\u001b[39m         }\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmodule_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1176\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\sentence_transformers\\models\\Transformer.py:262\u001b[39m, in \u001b[36mTransformer.forward\u001b[39m\u001b[34m(self, features, **kwargs)\u001b[39m\n\u001b[32m    239\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    240\u001b[39m \u001b[33;03mForward pass through the transformer model.\u001b[39;00m\n\u001b[32m    241\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    258\u001b[39m \u001b[33;03m        - 'all_layer_embeddings': If the model outputs hidden states, contains embeddings from all layers\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m trans_features = {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m features.items() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.model_forward_params}\n\u001b[32m--> \u001b[39m\u001b[32m262\u001b[39m outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mauto_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtrans_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    263\u001b[39m token_embeddings = outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    264\u001b[39m features[\u001b[33m\"\u001b[39m\u001b[33mtoken_embeddings\u001b[39m\u001b[33m\"\u001b[39m] = token_embeddings\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\jinaai\\jina_hyphen_bert_hyphen_v2_hyphen_qk_hyphen_post_hyphen_norm\\3baf9e3ac750e76e8edd3019170176884695fb94\\modeling_bert.py:1374\u001b[39m, in \u001b[36mJinaBertModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m   1365\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m   1367\u001b[39m embedding_output = \u001b[38;5;28mself\u001b[39m.embeddings(\n\u001b[32m   1368\u001b[39m     input_ids=input_ids,\n\u001b[32m   1369\u001b[39m     position_ids=position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1372\u001b[39m     past_key_values_length=past_key_values_length,\n\u001b[32m   1373\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1374\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1384\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1385\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1386\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m   1387\u001b[39m pooled_output = (\n\u001b[32m   1388\u001b[39m     \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1389\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\jinaai\\jina_hyphen_bert_hyphen_v2_hyphen_qk_hyphen_post_hyphen_norm\\3baf9e3ac750e76e8edd3019170176884695fb94\\modeling_bert.py:779\u001b[39m, in \u001b[36mJinaBertEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[39m\n\u001b[32m    769\u001b[39m     layer_outputs = torch.utils.checkpoint.checkpoint(\n\u001b[32m    770\u001b[39m         create_custom_forward(layer_module),\n\u001b[32m    771\u001b[39m         hidden_states,\n\u001b[32m   (...)\u001b[39m\u001b[32m    776\u001b[39m         alibi_bias,\n\u001b[32m    777\u001b[39m     )\n\u001b[32m    778\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m779\u001b[39m     layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    780\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    781\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    782\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    784\u001b[39m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    785\u001b[39m \u001b[43m        \u001b[49m\u001b[43malibi_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    786\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    787\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    790\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    791\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\jinaai\\jina_hyphen_bert_hyphen_v2_hyphen_qk_hyphen_post_hyphen_norm\\3baf9e3ac750e76e8edd3019170176884695fb94\\modeling_bert.py:658\u001b[39m, in \u001b[36mJinaBertLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, bias, past_key_value, output_attentions)\u001b[39m\n\u001b[32m    655\u001b[39m     present_key_value = present_key_value + cross_attn_present_key_value\n\u001b[32m    657\u001b[39m residual = \u001b[38;5;28mself\u001b[39m.layer_norm_1(residual + attention_output)\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m mlp_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmlp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m layer_output = \u001b[38;5;28mself\u001b[39m.layer_norm_2(residual + mlp_output)\n\u001b[32m    660\u001b[39m outputs = (layer_output,) + outputs\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.cache\\huggingface\\modules\\transformers_modules\\jinaai\\jina_hyphen_bert_hyphen_v2_hyphen_qk_hyphen_post_hyphen_norm\\3baf9e3ac750e76e8edd3019170176884695fb94\\modeling_bert.py:563\u001b[39m, in \u001b[36mJinaBertGLUMLP.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    561\u001b[39m hidden_mlp_states = \u001b[38;5;28mself\u001b[39m.dropout(hidden_mlp_states)\n\u001b[32m    562\u001b[39m \u001b[38;5;66;03m# Down\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m563\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdown_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_mlp_states\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1509\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1510\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1511\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1515\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1516\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1517\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1518\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1519\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1520\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1522\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1523\u001b[39m     result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\dev-copilot\\env\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    115\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Index the repository\n",
    "collection = index_repository(FLASK_REPO_PATH, force_reindex=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8785199",
   "metadata": {},
   "source": [
    "## 13. Example Searches\n",
    "\n",
    "Try different types of queries to see HyDE and RAG in action."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947a6a5",
   "metadata": {},
   "source": [
    "### Example 1: Topic Query (RAG) - \"How does Flask handle routing?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d62cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Search: RAG mode\n",
      "Query: 'How does Flask handle routing?'\n",
      "\n",
      " RAG Topic Query: 'How does Flask handle routing?'\n",
      "  → Retrieving relevant code chunks...\n",
      "  ✓ Retrieved 5 chunks\n",
      "  → Generating explanation via API...\n",
      "  ✓ Generated answer (538 characters)\n",
      "\n",
      "RAG Topic Query Result\n",
      "Query: How does Flask handle routing?\n",
      "\n",
      "Answer:\n",
      "Flask handles routing through the `url_map` attribute of the `Flask` application object, which is a central registry for URL rules. The `routes_command` function in `cli.py` iterates over the rules in `url_map` using the `iter_rules` method to show all registered routes with endpoints and methods. The `Flask` class in `app.py` acts as a central object that manages these URL rules, among other things. The actual routing is not shown in the provided code, but it is managed by the `Flask` application object and its `url_map` attribute.\n",
      "\n",
      "Supporting Sources (3):\n",
      "1. FUNCTION: routes_command\n",
      "   File: ../flask\\src\\flask\\cli.py:1069-1115\n",
      "   Similarity: 0.6147\n",
      "   Doc: Show all registered routes with endpoints and methods....\n",
      "   Code:\n",
      "      def routes_command(sort: str, all_methods: bool) -> None:\n",
      "          \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n",
      "          rules = list(current_app.url_map.iter_rules())\n",
      "\n",
      "2. FUNCTION: index\n",
      "   File: ../flask\\examples\\celery\\src\\task_app\\__init__.py:20-21\n",
      "   Similarity: 0.5577\n",
      "   Code:\n",
      "      def index() -> str:\n",
      "              return render_template(\"index.html\")\n",
      "\n",
      "3. CLASS: Flask\n",
      "   File: ../flask\\src\\flask\\app.py:82-1537\n",
      "   Similarity: 0.5507\n",
      "   Doc: The flask object implements a WSGI application and acts as the central\n",
      "    object.  It is passed the...\n",
      "   Code:\n",
      "      class Flask(App):\n",
      "          \"\"\"The flask object implements a WSGI application and acts as the central\n",
      "          object.  It is passed the name of the module or package of the\n",
      "          application.  Once it is created it will act as a central registry for\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Topic query - will use RAG\n",
    "query1 = \"How does Flask handle routing?\"\n",
    "result1 = smart_search(query1, top_k=5)\n",
    "display_search_result(result1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a54d6bb",
   "metadata": {},
   "source": [
    "### Example 2: Code Query (HyDE) - \"Show me route decorator implementation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6369bfaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Search: HYDE mode\n",
      "Query: 'Show me route decorator implementation'\n",
      "\n",
      " HyDE Code Search: 'Show me route decorator implementation'\n",
      "  → Generating hypothetical code via API...\n",
      "  ✓ Generated 479 characters of hypothetical code\n",
      "  → Embedding hypothetical code locally...\n",
      "  → Searching for similar code...\n",
      "  ✓ Found 5 results\n",
      "\n",
      "Found 5 code results:\n",
      "1. FUNCTION: decorator\n",
      "   File: ../flask\\src\\flask\\cli.py:395-400\n",
      "   Similarity: 0.6156 | Method: HyDE\n",
      "   Code Preview:\n",
      "      def decorator(ctx: click.Context, /, *args: t.Any, **kwargs: t.Any) -> t.Any:\n",
      "              if not current_app:\n",
      "                  app = ctx.ensure_object(ScriptInfo).load_app()\n",
      "                  ctx.with_resource(app.app_context())\n",
      "              return ctx.invoke(f, *args, **kwargs)\n",
      "\n",
      "2. FUNCTION: decorator\n",
      "   File: ../flask\\src\\flask\\helpers.py:108-110\n",
      "   Similarity: 0.5835 | Method: HyDE\n",
      "   Code Preview:\n",
      "      def decorator(*args: t.Any, **kwargs: t.Any) -> t.Any:\n",
      "                  gen = generator_or_function(*args, **kwargs)  # type: ignore[operator]\n",
      "                  return stream_with_context(gen)\n",
      "\n",
      "3. FUNCTION: decorator\n",
      "   File: ../flask\\src\\flask\\cli.py:422-425\n",
      "   Similarity: 0.5305 | Method: HyDE\n",
      "   Code Preview:\n",
      "      def decorator(f: t.Callable[..., t.Any]) -> click.Command:\n",
      "                  if wrap_for_ctx:\n",
      "                      f = with_appcontext(f)\n",
      "                  return super(AppGroup, self).command(*args, **kwargs)(f)  # type: ignore[no-any-return]\n",
      "\n",
      "4. FUNCTION: routes_command\n",
      "   File: ../flask\\src\\flask\\cli.py:1069-1115\n",
      "   Similarity: 0.4997 | Method: HyDE\n",
      "   Doc: Show all registered routes with endpoints and methods.\n",
      "   Code Preview:\n",
      "      def routes_command(sort: str, all_methods: bool) -> None:\n",
      "          \"\"\"Show all registered routes with endpoints and methods.\"\"\"\n",
      "          rules = list(current_app.url_map.iter_rules())\n",
      "          if not rules:\n",
      "              click.echo(\"No routes were registered.\")\n",
      "      ... (41 more lines)\n",
      "\n",
      "5. FUNCTION: login_required\n",
      "   File: ../flask\\examples\\tutorial\\flaskr\\auth.py:19-29\n",
      "   Similarity: 0.4971 | Method: HyDE\n",
      "   Doc: View decorator that redirects anonymous users to the login page.\n",
      "   Code Preview:\n",
      "      def login_required(view):\n",
      "          \"\"\"View decorator that redirects anonymous users to the login page.\"\"\"\n",
      "          @functools.wraps(view)\n",
      "          def wrapped_view(**kwargs):\n",
      "              if g.user is None:\n",
      "      ... (5 more lines)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Code query - will use HyDE\n",
    "query2 = \"Show me route decorator implementation\"\n",
    "result2 = smart_search(query2, top_k=5)\n",
    "display_search_result(result2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b4e6d4",
   "metadata": {},
   "source": [
    "### Example 3: Force Direct Search for Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ddf0fc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Search: DIRECT mode\n",
      "Query: 'error handling functions'\n",
      "Found 5 code results:\n",
      "1. CLASS: UnexpectedUnicodeError\n",
      "   File: ../flask\\src\\flask\\debughelpers.py:17-20\n",
      "   Similarity: 0.4215 | Method: Direct\n",
      "   Doc: Raised in places where we want some better error reporting for     unexpected unicode or binary data.\n",
      "   Code Preview:\n",
      "      class UnexpectedUnicodeError(AssertionError, UnicodeError):\n",
      "          \"\"\"Raised in places where we want some better error reporting for\n",
      "          unexpected unicode or binary data.\n",
      "          \"\"\"\n",
      "\n",
      "2. FUNCTION: _called_with_wrong_args\n",
      "   File: ../flask\\src\\flask\\cli.py:94-117\n",
      "   Similarity: 0.3834 | Method: Direct\n",
      "   Doc: Check whether calling a function raised a ``TypeError`` because     the call failed or because something in the factory raised the     error.      :pa...\n",
      "   Code Preview:\n",
      "      def _called_with_wrong_args(f: t.Callable[..., Flask]) -> bool:\n",
      "          \"\"\"Check whether calling a function raised a ``TypeError`` because\n",
      "          the call failed or because something in the factory raised the\n",
      "          error.\n",
      "          :param f: The function that was called.\n",
      "      ... (18 more lines)\n",
      "\n",
      "3. FUNCTION: _fail\n",
      "   File: ../flask\\src\\flask\\sessions.py:103-108\n",
      "   Similarity: 0.3832 | Method: Direct\n",
      "   Code Preview:\n",
      "      def _fail(self, *args: t.Any, **kwargs: t.Any) -> t.NoReturn:\n",
      "              raise RuntimeError(\n",
      "                  \"The session is unavailable because no secret \"\n",
      "                  \"key was set.  Set the secret_key on the \"\n",
      "                  \"application to something unique and secret.\"\n",
      "              )\n",
      "\n",
      "4. FUNCTION: __getitem__\n",
      "   File: ../flask\\src\\flask\\debughelpers.py:91-100\n",
      "   Similarity: 0.3735 | Method: Direct\n",
      "   Code Preview:\n",
      "      def __getitem__(self, key: str) -> t.Any:\n",
      "                  try:\n",
      "                      return super().__getitem__(key)\n",
      "                  except KeyError as e:\n",
      "                      if key not in request.form:\n",
      "                          raise\n",
      "      ... (4 more lines)\n",
      "\n",
      "5. FUNCTION: handle_user_exception\n",
      "   File: ../flask\\src\\flask\\app.py:780-810\n",
      "   Similarity: 0.3580 | Method: Direct\n",
      "   Doc: This method is called whenever an exception occurs that         should be handled. A special case is :class:`~werkzeug         .exceptions.HTTPExcepti...\n",
      "   Code Preview:\n",
      "      def handle_user_exception(\n",
      "              self, e: Exception\n",
      "          ) -> HTTPException | ft.ResponseReturnValue:\n",
      "              \"\"\"This method is called whenever an exception occurs that\n",
      "              should be handled. A special case is :class:`~werkzeug\n",
      "              .exceptions.HTTPException` which is forwarded to the\n",
      "      ... (25 more lines)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Force direct search to compare with HyDE\n",
    "query3 = \"error handling functions\"\n",
    "result3_direct = smart_search(query3, top_k=5, force_method='direct')\n",
    "display_search_result(result3_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7ecfc",
   "metadata": {},
   "source": [
    "### Example 4: Compare HyDE vs Direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af0da8fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### HyDE Search ###\n",
      "Smart Search: HYDE mode\n",
      "Query: 'request context management'\n",
      "\n",
      " HyDE Code Search: 'request context management'\n",
      "  → Generating hypothetical code via API...\n",
      "  ✓ Generated 648 characters of hypothetical code\n",
      "  → Embedding hypothetical code locally...\n",
      "  → Searching for similar code...\n",
      "  ✓ Found 5 results\n",
      "\n",
      "Found 5 code results:\n",
      "1. CLASS: RequestContext\n",
      "   File: ../flask\\src\\flask\\ctx.py:287-449\n",
      "   Similarity: 0.6628 | Method: HyDE\n",
      "   Doc: The request context contains per-request information. The Flask     app creates and pushes it at the beginning of the request, then pops     it at the...\n",
      "   Code Preview:\n",
      "      class RequestContext:\n",
      "          \"\"\"The request context contains per-request information. The Flask\n",
      "          app creates and pushes it at the beginning of the request, then pops\n",
      "          it at the end of the request. It will create the URL adapter and\n",
      "          request object for the WSGI environment provided.\n",
      "      ... (43 more lines)\n",
      "\n",
      "2. FUNCTION: copy_current_request_context\n",
      "   File: ../flask\\src\\flask\\ctx.py:155-193\n",
      "   Similarity: 0.6404 | Method: HyDE\n",
      "   Doc: A helper function that decorates a function to retain the current     request context.  This is useful when working with greenlets.  The moment     th...\n",
      "   Code Preview:\n",
      "      def copy_current_request_context(f: F) -> F:\n",
      "          \"\"\"A helper function that decorates a function to retain the current\n",
      "          request context.  This is useful when working with greenlets.  The moment\n",
      "          the function is decorated a copy of the request context is created and\n",
      "          then pushed when the function is called.  The current session is also\n",
      "          included in the copied request context.\n",
      "      ... (33 more lines)\n",
      "\n",
      "3. FUNCTION: __enter__\n",
      "   File: ../flask\\src\\flask\\ctx.py:433-435\n",
      "   Similarity: 0.6104 | Method: HyDE\n",
      "   Code Preview:\n",
      "      def __enter__(self) -> RequestContext:\n",
      "              self.push()\n",
      "              return self\n",
      "\n",
      "4. FUNCTION: __init__\n",
      "   File: ../flask\\src\\flask\\ctx.py:309-335\n",
      "   Similarity: 0.5958 | Method: HyDE\n",
      "   Code Preview:\n",
      "      def __init__(\n",
      "              self,\n",
      "              app: Flask,\n",
      "              environ: WSGIEnvironment,\n",
      "              request: Request | None = None,\n",
      "              session: SessionMixin | None = None,\n",
      "      ... (21 more lines)\n",
      "\n",
      "5. FUNCTION: has_request_context\n",
      "   File: ../flask\\src\\flask\\ctx.py:196-225\n",
      "   Similarity: 0.5921 | Method: HyDE\n",
      "   Doc: If you have code that wants to test if a request context is there or     not this function can be used.  For instance, you may want to take advantage ...\n",
      "   Code Preview:\n",
      "      def has_request_context() -> bool:\n",
      "          \"\"\"If you have code that wants to test if a request context is there or\n",
      "          not this function can be used.  For instance, you may want to take advantage\n",
      "          of request information if the request object is available, but fail\n",
      "          silently if it is unavailable.\n",
      "      ... (24 more lines)\n",
      "\n",
      "### Direct Search ###\n",
      "Smart Search: DIRECT mode\n",
      "Query: 'request context management'\n",
      "Found 5 code results:\n",
      "1. FUNCTION: __enter__\n",
      "   File: ../flask\\src\\flask\\ctx.py:433-435\n",
      "   Similarity: 0.6374 | Method: Direct\n",
      "   Code Preview:\n",
      "      def __enter__(self) -> RequestContext:\n",
      "              self.push()\n",
      "              return self\n",
      "\n",
      "2. FUNCTION: __init__\n",
      "   File: ../flask\\src\\flask\\ctx.py:309-335\n",
      "   Similarity: 0.5855 | Method: Direct\n",
      "   Code Preview:\n",
      "      def __init__(\n",
      "              self,\n",
      "              app: Flask,\n",
      "              environ: WSGIEnvironment,\n",
      "              request: Request | None = None,\n",
      "              session: SessionMixin | None = None,\n",
      "      ... (21 more lines)\n",
      "\n",
      "3. CLASS: RequestContext\n",
      "   File: ../flask\\src\\flask\\ctx.py:287-449\n",
      "   Similarity: 0.5593 | Method: Direct\n",
      "   Doc: The request context contains per-request information. The Flask     app creates and pushes it at the beginning of the request, then pops     it at the...\n",
      "   Code Preview:\n",
      "      class RequestContext:\n",
      "          \"\"\"The request context contains per-request information. The Flask\n",
      "          app creates and pushes it at the beginning of the request, then pops\n",
      "          it at the end of the request. It will create the URL adapter and\n",
      "          request object for the WSGI environment provided.\n",
      "      ... (43 more lines)\n",
      "\n",
      "4. FUNCTION: __init__\n",
      "   File: ../flask\\src\\flask\\ctx.py:245-249\n",
      "   Similarity: 0.5090 | Method: Direct\n",
      "   Code Preview:\n",
      "      def __init__(self, app: Flask) -> None:\n",
      "              self.app = app\n",
      "              self.url_adapter = app.create_url_adapter(None)\n",
      "              self.g: _AppCtxGlobals = app.app_ctx_globals_class()\n",
      "              self._cv_tokens: list[contextvars.Token[AppContext]] = []\n",
      "\n",
      "5. FUNCTION: __enter__\n",
      "   File: ../flask\\src\\flask\\ctx.py:274-276\n",
      "   Similarity: 0.5029 | Method: Direct\n",
      "   Code Preview:\n",
      "      def __enter__(self) -> AppContext:\n",
      "              self.push()\n",
      "              return self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compare HyDE vs Direct for the same query\n",
    "query4 = \"request context management\"\n",
    "\n",
    "print(\"### HyDE Search ###\")\n",
    "result4_hyde = smart_search(query4, top_k=5, force_method='hyde')\n",
    "display_search_result(result4_hyde)\n",
    "\n",
    "\n",
    "print(\"### Direct Search ###\")\n",
    "result4_direct = smart_search(query4, top_k=5, force_method='direct')\n",
    "display_search_result(result4_direct)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f60f8",
   "metadata": {},
   "source": [
    "## 14. Custom Search Interface\n",
    "\n",
    "Run your own queries here with automatic mode selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dca83dff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Smart Search: HYDE mode\n",
      "Query: 'What is the Blueprint class used for?'\n",
      "\n",
      " HyDE Code Search: 'What is the Blueprint class used for?'\n",
      "  → Generating hypothetical code via API...\n",
      "  ✓ Generated 488 characters of hypothetical code\n",
      "  → Embedding hypothetical code locally...\n",
      "  → Searching for similar code...\n",
      "  ✓ Found 5 results\n",
      "\n",
      "Found 5 code results:\n",
      "1. CLASS: Blueprint\n",
      "   File: ../flask\\src\\flask\\blueprints.py:18-128\n",
      "   Similarity: 0.7347 | Method: HyDE\n",
      "   Code Preview:\n",
      "      class Blueprint(SansioBlueprint):\n",
      "          def __init__(\n",
      "              self,\n",
      "              name: str,\n",
      "              import_name: str,\n",
      "              static_folder: str | os.PathLike[str] | None = None,\n",
      "      ... (50 more lines)\n",
      "\n",
      "2. FUNCTION: __init__\n",
      "   File: ../flask\\src\\flask\\blueprints.py:19-53\n",
      "   Similarity: 0.6421 | Method: HyDE\n",
      "   Code Preview:\n",
      "      def __init__(\n",
      "              self,\n",
      "              name: str,\n",
      "              import_name: str,\n",
      "              static_folder: str | os.PathLike[str] | None = None,\n",
      "              static_url_path: str | None = None,\n",
      "      ... (29 more lines)\n",
      "\n",
      "3. FUNCTION: __init__\n",
      "   File: ../flask\\src\\flask\\config.py:23-27\n",
      "   Similarity: 0.5538 | Method: HyDE\n",
      "   Code Preview:\n",
      "      def __init__(\n",
      "              self, name: str, get_converter: t.Callable[[t.Any], T] | None = None\n",
      "          ) -> None:\n",
      "              self.__name__ = name\n",
      "              self.get_converter = get_converter\n",
      "\n",
      "4. FUNCTION: create_app\n",
      "   File: ../flask\\examples\\tutorial\\flaskr\\__init__.py:6-51\n",
      "   Similarity: 0.5408 | Method: HyDE\n",
      "   Doc: Create and configure an instance of the Flask application.\n",
      "   Code Preview:\n",
      "      def create_app(test_config=None):\n",
      "          \"\"\"Create and configure an instance of the Flask application.\"\"\"\n",
      "          app = Flask(__name__, instance_relative_config=True)\n",
      "          app.config.from_mapping(\n",
      "              # a default secret that should be overridden by instance config\n",
      "              SECRET_KEY=\"dev\",\n",
      "      ... (40 more lines)\n",
      "\n",
      "5. CLASS: ConfigAttribute\n",
      "   File: ../flask\\src\\flask\\config.py:20-47\n",
      "   Similarity: 0.5251 | Method: HyDE\n",
      "   Doc: Makes an attribute forward to the config\n",
      "   Code Preview:\n",
      "      class ConfigAttribute(t.Generic[T]):\n",
      "          \"\"\"Makes an attribute forward to the config\"\"\"\n",
      "          def __init__(\n",
      "              self, name: str, get_converter: t.Callable[[t.Any], T] | None = None\n",
      "          ) -> None:\n",
      "      ... (22 more lines)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Custom search - modify the query below\n",
    "custom_query = \"What is the Blueprint class used for?\"\n",
    "custom_result = smart_search(custom_query, top_k=5)\n",
    "display_search_result(custom_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd85c9",
   "metadata": {},
   "source": [
    "## 15. Performance Analysis\n",
    "\n",
    "Compare HyDE, RAG, and Direct search quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d85de7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing Search Methods\n",
      "Query: 'template rendering'\n",
      "Suggested method: CODE\n",
      "\n",
      "1. HyDE Code Search\n",
      "\n",
      " HyDE Code Search: 'template rendering'\n",
      "  → Generating hypothetical code via API...\n",
      "  ✓ Generated 478 characters of hypothetical code\n",
      "  → Embedding hypothetical code locally...\n",
      "  → Searching for similar code...\n",
      "  ✓ Found 3 results\n",
      "\n",
      "Top result: index (similarity: 0.4885)\n",
      "2. Direct Search\n",
      "Top result: index (similarity: 0.4691)\n"
     ]
    }
   ],
   "source": [
    "def compare_search_methods(query: str, top_k: int = 5):\n",
    "    \"\"\"Compare all three search methods for a given query.\"\"\"\n",
    "    print(f\"Comparing Search Methods\")\n",
    "    print(f\"Query: '{query}'\")\n",
    "    \n",
    "    # Detect suggested method\n",
    "    suggested_type = detect_query_type(query)\n",
    "    print(f\"Suggested method: {suggested_type.upper()}\\n\")\n",
    "    \n",
    "    # Try HyDE\n",
    "    print(\"1. HyDE Code Search\")\n",
    "    hyde_results = hyde_code_search(query, top_k)\n",
    "    if hyde_results:\n",
    "        print(f\"Top result: {hyde_results[0]['name']} (similarity: {hyde_results[0]['similarity']:.4f})\")\n",
    "    \n",
    "    # Try Direct\n",
    "    print(\"2. Direct Search\")\n",
    "    direct_results = direct_search(query, top_k)\n",
    "    if direct_results:\n",
    "        print(f\"Top result: {direct_results[0]['name']} (similarity: {direct_results[0]['similarity']:.4f})\")\n",
    "    \n",
    "    # Try RAG (if topic query)\n",
    "    if suggested_type == 'topic':\n",
    "        print(\"3. RAG Topic Query\")\n",
    "        rag_result = rag_topic_query(query, top_k, context_chunks=3)\n",
    "        print(f\"Answer length: {len(rag_result['answer'])} characters\")\n",
    "        print(f\"Answer preview: {rag_result['answer'][:200]}...\")\n",
    "\n",
    "# Test comparison\n",
    "test_query = \"template rendering\"\n",
    "compare_search_methods(test_query, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400dfd43",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook implements advanced semantic code search with:\n",
    "\n",
    "✅ **Local Embedding**: Fast, offline embedding generation  \n",
    "✅ **API-Based HyDE**: Generate hypothetical code via API for better search relevance  \n",
    "✅ **API-Based RAG**: Retrieve context and generate explanations for topic queries  \n",
    "✅ **Automatic Mode Selection**: Smart detection of query type  \n",
    "✅ **Modular Design**: Easy to extend and customize  \n",
    "\n",
    "**Usage:**\n",
    "1. Index your repository once\n",
    "2. Use `smart_search()` for automatic mode selection\n",
    "3. Force specific methods with `force_method` parameter\n",
    "4. Compare methods with `compare_search_methods()`\n",
    "\n",
    "**Next Steps:**\n",
    "- Integrate into VS Code extension\n",
    "- Add caching for API responses\n",
    "- Implement hybrid search (BM25 + semantic)\n",
    "- Add user feedback collection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
